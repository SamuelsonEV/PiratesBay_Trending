{
 "cells": [
  {
   "cell_type": "raw",
   "id": "282c6344-fa4d-48fe-9480-17c5e30dade6",
   "metadata": {},
   "source": [
    "---\n",
    "title: Trending Torrents PiratesBay\n",
    "description: Latest trending torrents on PiratesBay \n",
    "show-code: True\n",
    "params:\n",
    "    limit:\n",
    "        input: slider\n",
    "        label: Limit number of Results\n",
    "        value: 100\n",
    "        min: 10\n",
    "        max: 300\n",
    "    cut_all_after:\n",
    "        input: select\n",
    "        label: Clip name after\n",
    "        value: ['HEVC','HDTV']\n",
    "        choices: ['720', '1080', 'H264', 'x264', '[', 'WEBRip', 'HEVC',\n",
    "                     'HDTV', 'x265']\n",
    "        multi: True\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530445c9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# those variables will be updated by Mercury framework\n",
    "limit = 100\n",
    "cut_all_after = ['HEVC','HDTV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a1c76-7b30-48a7-9034-69e621aed3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # Getting list of [name, magnectic_links]\n",
    "import requests\n",
    "import pandas as pd     #          <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<   Making a Pandas DF\n",
    "import os  # Check if have a old one and a new one to compare\n",
    "from operator import itemgetter\n",
    "from IPython.display import HTML  # Clean UP torrent strings\n",
    "import pickle  #  SAVE links_pages_data\n",
    "from datetime import datetime\n",
    "\n",
    "# Creating Folder to hold the old results to later comparison\n",
    "folder_path = \"./\"\n",
    "files_on_folder = os.listdir(folder_path)\n",
    "folder_name = \"trending_torrents\"\n",
    "if folder_name in files_on_folder:\n",
    "    print(\"Found \" + folder_name + \" using the existing one\")\n",
    "else:\n",
    "    print(\"Could not Found \" + folder_name + \" creating the directory\")\n",
    "    os.mkdir(folder_path + folder_name)\n",
    "files_on_folder = os.listdir(folder_path)\n",
    "files_path = folder_path + folder_name + \"/\"\n",
    "print(\"Will save on the folder: \" + files_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7b47b-54d1-4227-a3c2-38e8e592ee2e",
   "metadata": {},
   "source": [
    "## Acquiring HTML of the PiratesBay's first 35 pages\n",
    "* Classified by number of leachers (Since number of seeders there is a lot of spoofed torrents)  \n",
    "\n",
    "\"list_of_name_mlinks\" is the results list composed of [[name, mlink],[name, mlink],[name, mlink],[name, mlink]...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add06ed-5766-482e-a285-14d10ee9c0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_pages = 35\n",
    "url_base = \"https://pirateproxy.live/browse/200/{}/9\"\n",
    "list_of_name_mlinks = []\n",
    "for page_num in range(1, number_of_pages + 1):\n",
    "    r = requests.get(url_base.format(page_num))\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    tst = soup.find_all(\"tr\")\n",
    "    tst2 = tst[1:-1]\n",
    "    result_page = []\n",
    "    for it in range(len(tst2)):\n",
    "#         print(\"'\" + tst2[it].find_all(\"div\", {\"class\": \"detName\"})[0].text[1:-1] + \"'\")\n",
    "#         print(tst2[1].find_all(\"a\")[3]['href'])\n",
    "        name = tst2[it].find_all(\"div\", {\"class\": \"detName\"})[0].text[1:-1]\n",
    "        mlink = tst2[1].find_all(\"a\")[3]['href']\n",
    "        list_of_name_mlinks.append([name, mlink])\n",
    "print(len(list_of_name_mlinks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c981f-8890-4c7b-8861-5692356a1cf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Pandas Data Frame and saving it to a picklefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640a572-6486-4423-a1de-ab3e38291b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "torrents = pd.DataFrame(list_of_name_mlinks, columns = [\"Name\", \"Mag Link\"])\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "with open( files_path + 'ptorrent_' + dt_string + '.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(torrents, f)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980dae72-8f73-48ae-811c-b126be4dbadf",
   "metadata": {},
   "source": [
    "## Search on the folder for latest to compare with the actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f834287-6e9c-4f1e-9cc3-21443f8f042c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_on_folder = os.listdir(files_path)\n",
    "to_scrape_folders = []\n",
    "for item in files_on_folder:\n",
    "    if item.find(\"ptorrent_\") == 0:\n",
    "#         print(\"'\" + item[9:item.rfind(\".\")] + \"'\")\n",
    "        date_time_str = item[9:item.rfind(\".\")]\n",
    "        date_time_obj = datetime.strptime(date_time_str, '%d-%m-%Y_%H:%M:%S')\n",
    "        to_scrape_folders.append([files_path + item , date_time_obj])\n",
    "for it in to_scrape_folders:\n",
    "    print(it)\n",
    "print(\"-------------------------------------------------\")\n",
    "if len(to_scrape_folders) > 1:\n",
    "    to_scrape_folders = sorted(to_scrape_folders, key=itemgetter(1))  # Put in DateTime ORDER !!!!!!\n",
    "    for n in range(len(to_scrape_folders)):                           # Print Epochs and time difference betwen them\n",
    "        print(\"Epoch from date : \" + str(to_scrape_folders[n][1]))\n",
    "        if to_scrape_folders[n] != to_scrape_folders[-1]:\n",
    "            print(\"time passed:>    \" + str(to_scrape_folders[n+1][1] - to_scrape_folders[n][1]))\n",
    "    print(\"Have More than one to compare !!!!!\")\n",
    "else:\n",
    "    print(\"DON`T Have More than one to compare !!!!!\")\n",
    "    raise SystemExit(\"DON`T Have More than one to compare !!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a95b05-b624-4525-a970-558a3124fa4e",
   "metadata": {},
   "source": [
    "## Open both to make comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145310d9-c830-474f-917b-749226ab8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(to_scrape_folders[-2][0], 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    print(to_scrape_folders[-2][0])\n",
    "    product_list_old = pickle.load(f)\n",
    "f.close\n",
    "with open(to_scrape_folders[-1][0], 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    print(to_scrape_folders[-1][0])\n",
    "    product_list_new = pickle.load(f)\n",
    "f.close\n",
    "to_compare = product_list_new\n",
    "# to_scrape_folders[-2][1].strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "to_compare[[to_scrape_folders[-2][1].strftime(\"%d-%m-%Y_%H:%M:%S\")]] = None\n",
    "# [[to_scrape_folders[n+1][1].strftime(\"%d-%m-%Y_%H:%M:%S\")]] = np.nan  # Add a new Column with the name being the datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31da8a-3918-4cc0-a9ed-5fa9d50c0874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f354e-60d0-4d1d-bc26-30414fb764b3",
   "metadata": {},
   "source": [
    "## Find the latest position (index) of each torrent and compare with the actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd172240-c47d-4326-92c7-20d023c822f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_products in product_list_old.index:    # Add to the comparation table the index from the old one\n",
    "    to_compare.loc[((to_compare['Name'] == product_list_old.loc[index_products,'Name'])), \\\n",
    "                        to_scrape_folders[-2][1].strftime(\"%d-%m-%Y_%H:%M:%S\")] = int(index_products)\n",
    "#     to_compare.loc[((to_compare['Name'] == product_list_old.loc[index_products,'Name']) & \\\n",
    "#                         (to_compare['Mag Link'] == product_list_old.loc[index_products,'Mag Link'])), \\\n",
    "#                         to_scrape_folders[-2][1].strftime(\"%d-%m-%Y_%H:%M:%S\")] = int(index_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96841b5e-45dc-4cdd-9728-095477d9e15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b02188-9660-4a3c-a7e6-cf43dc425bf4",
   "metadata": {},
   "source": [
    "## Compare Actual results with old one and save difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266a444-0209-40e7-9f7c-c871cb510028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_compare[[\"diff\"]] = None\n",
    "for index_products in to_compare.index:  # Calculate the Diff column\n",
    "    old_datetime = to_scrape_folders[-2][1].strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "    if to_compare.loc[index_products, old_datetime] is None:\n",
    "        to_compare.loc[index_products, old_datetime] = len(to_compare.index)\n",
    "    if index_products != to_compare.loc[index_products, old_datetime]:\n",
    "#         print(to_compare.loc[index_products])\n",
    "        to_compare.loc[index_products, \"diff\"] = to_compare.loc[index_products, old_datetime]- index_products\n",
    "    if index_products == to_compare.loc[index_products, old_datetime]:\n",
    "        to_compare.loc[index_products, \"diff\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816b937-e750-4d41-b310-ac8d76ce8f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef744bf-8fd6-407d-9b09-a6a3e5d6cce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sort by torrents that had gone up(Trending) and clean name strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1af520-c58d-4ef5-84fe-5037c636aec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  # Clean UP torrent strings\n",
    "result = to_compare.sort_values(by='diff', ascending=False)[:limit] # <<<<<<<<<<<<<<< limit here result \n",
    "for it in result.index:  # Regex to clean Name String\n",
    "    modified_string = False\n",
    "    name = result.loc[it]['Name']\n",
    "    for filt in cut_all_after:\n",
    "        if name.find(filt) != -1:\n",
    "            modified_string = True\n",
    "            name = name[:name.find(filt)]\n",
    "    if modified_string is False:\n",
    "        name = name\n",
    "    result.loc[[it], 'Name'] = '<a href=\"https://www.google.com/search?q={}\">{}</a>'.format(name,name)\n",
    "    result.loc[[it], 'Mag Link'] = '<a href=\"{}\">\"Magnectic Link\"</a>'.format(result.loc[it]['Mag Link'])\n",
    "HTML(result.to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5567a-942f-4544-a0ac-e5380f1b2a6c",
   "metadata": {},
   "source": [
    "# FINISH -------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
